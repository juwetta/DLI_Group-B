{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMgzNiqhs2SWx7EIuIMXtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juwetta/DLI_Group-B/blob/main/TP074003_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Dataset: The dataset is loaded into a pandas DataFrame, and the features (X) and the target variable (y) are extracted. The features appear to include columns 3 to the second-to-last column, and the target variable is the last column."
      ],
      "metadata": {
        "id": "_Z0UPouuW_Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Assignment/URL_dataset_clean_balanced.csv')\n",
        "\n",
        "\n",
        "display(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Ynu6faJoW8dK",
        "outputId": "f0a6e03e-ed5d-4b46-cbe0-dd5db8d3087e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                      url        type\n",
              "0                                    http://kitegacc.net/    phishing\n",
              "1       https://www.electronichouse.com/article/ps3_ad...  legitimate\n",
              "2           https://www.linkedin.com/in/larrymartinkimpel  legitimate\n",
              "3       https://www.kansascity.com/2011/03/05/2700249/...  legitimate\n",
              "4             https://www.en.wikipedia.org/wiki/Dem_Bones  legitimate\n",
              "...                                                   ...         ...\n",
              "208871  http://www.apsweb.co.jp/wordpress/ihup/nD/inde...    phishing\n",
              "208872               https://www.theruckus.wordpress.com/  legitimate\n",
              "208873        http://jambidaily.com/34g3f3g/68k7jh65g.exe    phishing\n",
              "208874               http://ejanla.co/43543r34r/843tf.exe    phishing\n",
              "208875                     http://sadovod-gel.ru/43h36n54    phishing\n",
              "\n",
              "[208876 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ca83f29-6c48-46f3-a795-21e775fed93d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://kitegacc.net/</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.electronichouse.com/article/ps3_ad...</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.linkedin.com/in/larrymartinkimpel</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.kansascity.com/2011/03/05/2700249/...</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.en.wikipedia.org/wiki/Dem_Bones</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208871</th>\n",
              "      <td>http://www.apsweb.co.jp/wordpress/ihup/nD/inde...</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208872</th>\n",
              "      <td>https://www.theruckus.wordpress.com/</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208873</th>\n",
              "      <td>http://jambidaily.com/34g3f3g/68k7jh65g.exe</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208874</th>\n",
              "      <td>http://ejanla.co/43543r34r/843tf.exe</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208875</th>\n",
              "      <td>http://sadovod-gel.ru/43h36n54</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208876 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca83f29-6c48-46f3-a795-21e775fed93d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ca83f29-6c48-46f3-a795-21e775fed93d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ca83f29-6c48-46f3-a795-21e775fed93d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6fe99450-7210-4f31-90d7-0676b2661c8e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6fe99450-7210-4f31-90d7-0676b2661c8e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6fe99450-7210-4f31-90d7-0676b2661c8e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d3bad7c6-43a1-4e4d-ba76-61bf8d2699b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d3bad7c6-43a1-4e4d-ba76-61bf8d2699b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minisom\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 1: Import libraries & dataset\n",
        "# ================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from minisom import MiniSom\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Assignment/URL_dataset_clean_balanced.csv')\n",
        "\n",
        "# Inspect\n",
        "print(dataset.head())\n",
        "print(dataset.info())\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_url_features(url):\n",
        "    \"\"\"Extracts various features from a URL.\"\"\"\n",
        "    features = {}\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "\n",
        "        features['url_length'] = len(url)\n",
        "        features['num_dots'] = url.count('.')\n",
        "        features['has_at_symbol'] = '@' in url\n",
        "        features['has_double_slash'] = '//' in url\n",
        "        features['num_dashes'] = url.count('-')\n",
        "        features['num_underscores'] = url.count('_')\n",
        "        features['num_equals'] = url.count('=')\n",
        "        features['num_semicolons'] = url.count(';')\n",
        "        features['num_commas'] = url.count(',')\n",
        "        features['num_quotes'] = url.count(\"'\") + url.count('\"')\n",
        "        features['num_less_than'] = url.count('<')\n",
        "        features['num_greater_than'] = url.count('>')\n",
        "        features['num_braces'] = url.count('{') + url.count('}')\n",
        "        features['num_brackets'] = url.count('[') + url.count(']')\n",
        "        features['num_parentheses'] = url.count('(') + url.count(')')\n",
        "        features['num_hashes'] = url.count('#')\n",
        "        features['num_exclamations'] = url.count('!')\n",
        "        features['num_dollars'] = url.count('$')\n",
        "        features['num_spaces'] = url.count(' ')\n",
        "        features['num_slashes'] = url.count('/')\n",
        "        features['num_questions'] = url.count('?')\n",
        "        features['num_and'] = url.count('&')\n",
        "        features['num_or'] = url.count('|')\n",
        "        features['num_tilde'] = url.count('~')\n",
        "        features['num_http'] = url.count('http') + url.count('https')\n",
        "        features['num_www'] = url.count('www')\n",
        "        features['num_subdomains'] = len(parsed_url.hostname.split('.')) - 2 if parsed_url.hostname else 0 # Subtract 2 for domain and TLD\n",
        "        features['path_length'] = len(parsed_url.path)\n",
        "        features['query_length'] = len(parsed_url.query)\n",
        "        features['fragment_length'] = len(parsed_url.fragment)\n",
        "        features['has_ip_address'] = bool(re.match(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', parsed_url.hostname)) if parsed_url.hostname else False\n",
        "\n",
        "    except ValueError:\n",
        "        # Return a series of zeros if the URL is invalid\n",
        "        return pd.Series({\n",
        "            'url_length': 0, 'num_dots': 0, 'has_at_symbol': False, 'has_double_slash': False,\n",
        "            'num_dashes': 0, 'num_underscores': 0, 'num_equals': 0, 'num_semicolons': 0,\n",
        "            'num_commas': 0, 'num_quotes': 0, 'num_less_than': 0, 'num_greater_than': 0,\n",
        "            'num_braces': 0, 'num_brackets': 0, 'num_parentheses': 0, 'num_hashes': 0,\n",
        "            'num_exclamations': 0, 'num_dollars': 0, 'num_spaces': 0, 'num_slashes': 0,\n",
        "            'num_questions': 0, 'num_and': 0, 'num_or': 0, 'num_tilde': 0, 'num_http': 0,\n",
        "            'num_www': 0, 'num_subdomains': 0, 'path_length': 0, 'query_length': 0,\n",
        "            'fragment_length': 0, 'has_ip_address': False\n",
        "        })\n",
        "\n",
        "    return pd.Series(features)\n",
        "\n",
        "# Apply the feature extraction function to the 'url' column\n",
        "features_df = dataset['url'].apply(extract_url_features)\n",
        "\n",
        "# Convert boolean columns to numeric (0s and 1s) for RMO/SOM\n",
        "for col in features_df.columns:\n",
        "    if features_df[col].dtype == 'bool':\n",
        "        features_df[col] = features_df[col].astype(int)\n",
        "\n",
        "\n",
        "# Split into features & labels\n",
        "X = features_df.values\n",
        "y = dataset['type'].values\n",
        "\n",
        "\n",
        "# Normalize the features before RMO-SOM\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 2: Feature extraction with SOM-RMO\n",
        "# ================================\n",
        "\n",
        "def rmo_som_feature_extraction(features, num_neurons, num_rmo_iterations, learning_rate_start, neighborhood_radius_start, rmo_beta=0.5, rmo_alpha=0.8):\n",
        "    \"\"\"\n",
        "    Performs feature extraction using SOM optimized with RMO principles.\n",
        "    This is a simulated implementation of RMO influencing SOM weight updates.\n",
        "\n",
        "    Args:\n",
        "        features (np.ndarray): The input features (scaled).\n",
        "        num_neurons (int): The number of neurons in the SOM.\n",
        "        num_rmo_iterations (int): The number of RMO iterations (outer loop).\n",
        "        learning_rate_start (float): The initial learning rate for SOM updates (inner loop).\n",
        "        neighborhood_radius_start (float): The initial neighborhood radius for SOM updates (inner loop).\n",
        "        rmo_beta (float): RMO parameter influencing movement towards best.\n",
        "        rmo_alpha (float): RMO parameter influencing random movement.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The extracted features after SOM-RMO.\n",
        "    \"\"\"\n",
        "    # Ensure features are float type\n",
        "    features = features.astype(float)\n",
        "\n",
        "    num_features = features.shape[1]\n",
        "    som_weights = np.random.rand(num_neurons, num_features).astype(float) # Ensure float type\n",
        "\n",
        "    # Initialize best weights found so far\n",
        "    best_som_weights = som_weights.copy()\n",
        "    # In a real RMO-SOM, you would need a fitness function to evaluate SOM quality\n",
        "    # and determine the 'best'. For this simulation, we'll conceptually update\n",
        "    # 'best_som_weights' based on the RMO movement idea, but without a true fitness.\n",
        "\n",
        "\n",
        "    for rmo_iter in range(num_rmo_iterations):\n",
        "        # Adjust SOM learning rate and neighborhood radius over RMO iterations (optional, but common)\n",
        "        current_learning_rate = learning_rate_start * np.exp(-rmo_iter / num_rmo_iterations)\n",
        "        current_neighborhood_radius = neighborhood_radius_start * np.exp(-rmo_iter / num_rmo_iterations)\n",
        "\n",
        "        # --- Simulate SOM training step influenced by RMO ---\n",
        "        # Instead of full SOM epochs here, we'll update weights based on a random data point\n",
        "        # and influence from the 'best' weights found so far (RMO principle).\n",
        "\n",
        "        # Select a random data point\n",
        "        random_data_point_index = np.random.randint(0, features.shape[0])\n",
        "        random_data_point = np.array(features[random_data_point_index]).astype(float) # Ensure float type\n",
        "\n",
        "        # Find BMU for the current SOM weights\n",
        "        bmu_index = np.argmin(np.linalg.norm(som_weights - random_data_point, axis=1))\n",
        "\n",
        "        # Update weights of the current SOM based on BMU and neighborhood (SOM principle)\n",
        "        for i in range(num_neurons):\n",
        "            weight_vector = np.array(som_weights[i]).astype(float) # Ensure float type\n",
        "            bmu_weight_vector = np.array(som_weights[bmu_index]).astype(float) # Ensure float type\n",
        "            data_point_vector = np.array(random_data_point).astype(float) # Ensure float type\n",
        "\n",
        "\n",
        "            distance_to_bmu = np.linalg.norm(weight_vector - bmu_weight_vector)\n",
        "            influence = np.exp(-distance_to_bmu**2 / (2 * current_neighborhood_radius**2))\n",
        "\n",
        "            # --- RMO-like Update Rule ---\n",
        "            # This simulates movement towards the 'best_som_weights' and incorporates a random component.\n",
        "            # The specific RMO update rule can vary. This is a simplified version.\n",
        "            rmo_movement = (\n",
        "                rmo_beta * np.random.rand() * (best_som_weights[i] - weight_vector) + # Movement towards best\n",
        "                rmo_alpha * np.random.rand() * (data_point_vector - weight_vector)    # Movement towards data point (SOM-like)\n",
        "            )\n",
        "\n",
        "            # Combine SOM influence with RMO movement\n",
        "            som_weights[i] += current_learning_rate * influence * rmo_movement\n",
        "\n",
        "        # --- Update best_som_weights (Conceptual) ---\n",
        "        # In a real RMO, you would evaluate the fitness of 'som_weights' here\n",
        "        # and update 'best_som_weights' if it's better. Without a fitness function,\n",
        "        # we'll make a simplifying assumption or skip a true 'best' update.\n",
        "        # For a simulation, we could periodically update best_som_weights\n",
        "        # based on the current som_weights, though this isn't true RMO.\n",
        "        # Let's assume a mechanism exists to update best_som_weights (e.g., based on error).\n",
        "        # For this code, we'll just let the RMO movement guide the single set of weights.\n",
        "        best_som_weights = som_weights.copy() # Simplified: best is always current\n",
        "\n",
        "    # After RMO iterations, use the final som_weights for feature extraction.\n",
        "    final_som_weights = som_weights\n",
        "\n",
        "\n",
        "    # Extract features by mapping data points to the trained SOM weights\n",
        "    extracted_features = np.zeros((features.shape[0], num_features))\n",
        "    for i in range(features.shape[0]):\n",
        "        feature_vector = np.array(features[i]).astype(float) # Ensure float type\n",
        "        bmu_index = np.argmin(np.linalg.norm(final_som_weights - feature_vector, axis=1))\n",
        "        extracted_features[i] = final_som_weights[bmu_index]\n",
        "\n",
        "    return extracted_features\n",
        "\n",
        "\n",
        "# Define SOM-RMO parameters based on Table 8\n",
        "num_som_neurons = 10 * 10  # Grid Size SOM 10x10 = 100 neurons\n",
        "num_rmo_iterations = 1000  # Number of Iterations 1000\n",
        "initial_learning_rate = 0.5 # Learning Rate 0.5\n",
        "initial_neighborhood_radius = 5.0 # Radius 5.0\n",
        "# rmo_beta and rmo_alpha parameters are not explicitly in Table 8, keeping previous values\n",
        "\n",
        "\n",
        "# Apply SOM-RMO for feature extraction\n",
        "# X_scaled is the normalized features from the previous cell\n",
        "som_features = rmo_som_feature_extraction(X_scaled, num_som_neurons, num_rmo_iterations, initial_learning_rate, initial_neighborhood_radius)\n",
        "\n",
        "# Display the shape of the extracted features\n",
        "print(\"Shape of SOM-RMO extracted features:\", som_features.shape)\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 3: Classification with RBFN\n",
        "# ================================\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(som_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initial RBF transformation parameters based on Table 8\n",
        "# Number of Centers 100 -> n_components=100\n",
        "# Gamma is not explicitly in the RBFN section of Table 8, keeping default or previous value\n",
        "rbf_feature = RBFSampler(gamma=1, n_components=100, random_state=42)\n",
        "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "# Initial classifier (Logistic Regression) parameters based on Table 8\n",
        "# Epochs 500 -> max_iter=500\n",
        "# Learning Rate and Momentum are for RBFN training, not directly applicable to Logistic Regression\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train_rbf, y_train)\n",
        "y_pred = clf.predict(X_test_rbf)\n",
        "print(\"Baseline Accuracy (after SOM-RMO feature extraction):\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 4: Tabu Search Optimization for RBFN\n",
        "# ================================\n",
        "import random\n",
        "\n",
        "def evaluate_solution(gamma, n_components):\n",
        "    \"\"\"Train RBFN with given hyperparameters and return accuracy\"\"\"\n",
        "    rbf_feature = RBFSampler(gamma=gamma, n_components=n_components, random_state=42)\n",
        "    X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "    X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "    # Use Logistic Regression as the classifier with max_iter from Table 8\n",
        "    clf = LogisticRegression(max_iter=500)\n",
        "    clf.fit(X_train_rbf, y_train)\n",
        "    y_pred = clf.predict(X_test_rbf)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Tabu Search Parameters based on Table 8\n",
        "tabu_list = []\n",
        "tabu_size = 50 # List Size Tabu 50\n",
        "num_iterations = 100 # Search Iterations 100\n",
        "\n",
        "# Initial solution\n",
        "best_gamma = 1\n",
        "best_n_components = 100 # Initial n_components based on Table 8\n",
        "best_acc = evaluate_solution(best_gamma, best_n_components)\n",
        "\n",
        "print(f\"Initial RBFN solution (before Tabu Search): gamma={best_gamma}, n_components={best_n_components}, acc={best_acc:.4f}\")\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Generate neighbor solutions\n",
        "    # Using smaller steps for generating neighbors based on previous successful run\n",
        "    candidate_gamma = best_gamma + random.choice([-0.1, 0.1])\n",
        "    candidate_n_components = best_n_components + random.choice([-10, 10])\n",
        "\n",
        "    # Bounds (keeping reasonable bounds)\n",
        "    candidate_gamma = max(0.01, min(10, candidate_gamma))\n",
        "    candidate_n_components = max(10, min(500, candidate_n_components)) # Adjusted max bound\n",
        "\n",
        "\n",
        "    # Check tabu list\n",
        "    if (candidate_gamma, candidate_n_components) in tabu_list:\n",
        "        continue\n",
        "\n",
        "    # Evaluate candidate\n",
        "    acc = evaluate_solution(candidate_gamma, candidate_n_components)\n",
        "    # print(f\"Iteration {iteration+1}: gamma={candidate_gamma}, n_components={candidate_n_components}, acc={acc:.4f}\") # Suppress verbose output\n",
        "\n",
        "    # Update best\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_gamma = candidate_gamma\n",
        "        best_n_components = candidate_n_components\n",
        "\n",
        "    # Update tabu list\n",
        "    tabu_list.append((candidate_gamma, candidate_n_components))\n",
        "    if len(tabu_list) > tabu_size:\n",
        "        tabu_list.pop(0)\n",
        "\n",
        "print(f\"Optimized RBFN solution (after Tabu Search): gamma={best_gamma}, n_components={best_n_components}, acc={best_acc:.4f}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 5: Final Evaluation\n",
        "# ================================\n",
        "rbf_feature = RBFSampler(gamma=best_gamma, n_components=best_n_components, random_state=42)\n",
        "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=500) # Using max_iter from Table 8\n",
        "clf.fit(X_train_rbf, y_train)\n",
        "y_pred = clf.predict(X_test_rbf)\n",
        "\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZcOYO2ChQHK",
        "outputId": "15f9625a-02d2-46c0-89d4-81234203b3b3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: minisom in /usr/local/lib/python3.12/dist-packages (2.3.5)\n",
            "                                                 url        type\n",
            "0                               http://kitegacc.net/    phishing\n",
            "1  https://www.electronichouse.com/article/ps3_ad...  legitimate\n",
            "2      https://www.linkedin.com/in/larrymartinkimpel  legitimate\n",
            "3  https://www.kansascity.com/2011/03/05/2700249/...  legitimate\n",
            "4        https://www.en.wikipedia.org/wiki/Dem_Bones  legitimate\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208876 entries, 0 to 208875\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   url     208876 non-null  object\n",
            " 1   type    208876 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.2+ MB\n",
            "None\n",
            "Shape of SOM-RMO extracted features: (208876, 31)\n",
            "Baseline Accuracy (after SOM-RMO feature extraction): 0.9364707008808886\n",
            "Initial RBFN solution (before Tabu Search): gamma=1, n_components=100, acc=0.9365\n",
            "Optimized RBFN solution (after Tabu Search): gamma=1.1, n_components=110, acc=0.9386\n",
            "\n",
            "Final Model Performance:\n",
            "Accuracy: 0.9386250478743776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  legitimate       0.91      0.97      0.94     20862\n",
            "    phishing       0.97      0.91      0.94     20914\n",
            "\n",
            "    accuracy                           0.94     41776\n",
            "   macro avg       0.94      0.94      0.94     41776\n",
            "weighted avg       0.94      0.94      0.94     41776\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1210f4a7"
      },
      "source": [
        "## Load dataset and initial feature extraction\n",
        "\n",
        "### Subtask:\n",
        "Load the dataset and perform initial feature extraction from the URLs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90a5c78d"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to load the dataset and perform the initial feature extraction as outlined in the instructions. This involves importing necessary libraries, loading the data, defining the feature extraction function, and applying it to the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac9b1da",
        "outputId": "e2008375-0cdc-4080-d7cf-48e8e41bb16a"
      },
      "source": [
        "!pip install minisom\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 1: Import libraries & dataset\n",
        "# ================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from minisom import MiniSom\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Assignment/URL_dataset_clean_balanced.csv')\n",
        "\n",
        "# Inspect\n",
        "print(dataset.head())\n",
        "print(dataset.info())\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_url_features(url):\n",
        "    \"\"\"Extracts various features from a URL.\"\"\"\n",
        "    features = {}\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "\n",
        "        features['url_length'] = len(url)\n",
        "        features['num_dots'] = url.count('.')\n",
        "        features['has_at_symbol'] = '@' in url\n",
        "        features['has_double_slash'] = '//' in url\n",
        "        features['num_dashes'] = url.count('-')\n",
        "        features['num_underscores'] = url.count('_')\n",
        "        features['num_equals'] = url.count('=')\n",
        "        features['num_semicolons'] = url.count(';')\n",
        "        features['num_commas'] = url.count(',')\n",
        "        features['num_quotes'] = url.count(\"'\") + url.count('\"')\n",
        "        features['num_less_than'] = url.count('<')\n",
        "        features['num_greater_than'] = url.count('>')\n",
        "        features['num_braces'] = url.count('{') + url.count('}')\n",
        "        features['num_brackets'] = url.count('[') + url.count(']')\n",
        "        features['num_parentheses'] = url.count('(') + url.count(')')\n",
        "        features['num_hashes'] = url.count('#')\n",
        "        features['num_exclamations'] = url.count('!')\n",
        "        features['num_dollars'] = url.count('$')\n",
        "        features['num_spaces'] = url.count(' ')\n",
        "        features['num_slashes'] = url.count('/')\n",
        "        features['num_questions'] = url.count('?')\n",
        "        features['num_and'] = url.count('&')\n",
        "        features['num_or'] = url.count('|')\n",
        "        features['num_tilde'] = url.count('~')\n",
        "        features['num_http'] = url.count('http') + url.count('https')\n",
        "        features['num_www'] = url.count('www')\n",
        "        features['num_subdomains'] = len(parsed_url.hostname.split('.')) - 2 if parsed_url.hostname else 0 # Subtract 2 for domain and TLD\n",
        "        features['path_length'] = len(parsed_url.path)\n",
        "        features['query_length'] = len(parsed_url.query)\n",
        "        features['fragment_length'] = len(parsed_url.fragment)\n",
        "        features['has_ip_address'] = bool(re.match(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', parsed_url.hostname)) if parsed_url.hostname else False\n",
        "\n",
        "    except ValueError:\n",
        "        # Return a series of zeros if the URL is invalid\n",
        "        return pd.Series({\n",
        "            'url_length': 0, 'num_dots': 0, 'has_at_symbol': False, 'has_double_slash': False,\n",
        "            'num_dashes': 0, 'num_underscores': 0, 'num_equals': 0, 'num_semicolons': 0,\n",
        "            'num_commas': 0, 'num_quotes': 0, 'num_less_than': 0, 'num_greater_than': 0,\n",
        "            'num_braces': 0, 'num_brackets': 0, 'num_parentheses': 0, 'num_hashes': 0,\n",
        "            'num_exclamations': 0, 'num_dollars': 0, 'num_spaces': 0, 'num_slashes': 0,\n",
        "            'num_questions': 0, 'num_and': 0, 'num_or': 0, 'num_tilde': 0, 'num_http': 0,\n",
        "            'num_www': 0, 'num_subdomains': 0, 'path_length': 0, 'query_length': 0,\n",
        "            'fragment_length': 0, 'has_ip_address': False\n",
        "        })\n",
        "\n",
        "    return pd.Series(features)\n",
        "\n",
        "# Apply the feature extraction function to the 'url' column\n",
        "features_df = dataset['url'].apply(extract_url_features)\n",
        "\n",
        "\n",
        "# Split into features & labels\n",
        "X = features_df.values\n",
        "y = dataset['type'].values\n",
        "\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 2: Feature extraction with SOM (simulating SOM-RMO)\n",
        "# ================================\n",
        "som = MiniSom(x=10, y=10, input_len=X_scaled.shape[1], sigma=1.0, learning_rate=0.5)\n",
        "som.random_weights_init(X_scaled)\n",
        "som.train_random(X_scaled, num_iteration=100)\n",
        "\n",
        "# Map inputs to BMU (Best Matching Unit)\n",
        "som_features = np.array([som.winner(x) for x in X_scaled])\n",
        "\n",
        "# Flatten 2D coordinates (x,y) → single feature vector\n",
        "som_features = np.array([list(f) for f in som_features])\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 3: Classification with RBFN\n",
        "# ================================\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(som_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initial RBF transformation\n",
        "rbf_feature = RBFSampler(gamma=1, n_components=100, random_state=42)\n",
        "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "# Initial classifier\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train_rbf, y_train)\n",
        "y_pred = clf.predict(X_test_rbf)\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 4: Tabu Search Optimization for RBFN\n",
        "# ================================\n",
        "import random\n",
        "\n",
        "def evaluate_solution(gamma, n_components):\n",
        "    \"\"\"Train RBFN with given hyperparameters and return accuracy\"\"\"\n",
        "    rbf_feature = RBFSampler(gamma=gamma, n_components=n_components, random_state=42)\n",
        "    X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "    X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "    clf = LogisticRegression(max_iter=500)\n",
        "    clf.fit(X_train_rbf, y_train)\n",
        "    y_pred = clf.predict(X_test_rbf)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Tabu Search Parameters\n",
        "tabu_list = []\n",
        "tabu_size = 5\n",
        "num_iterations = 20\n",
        "\n",
        "# Initial solution\n",
        "best_gamma = 1\n",
        "best_n_components = 100\n",
        "best_acc = evaluate_solution(best_gamma, best_n_components)\n",
        "\n",
        "print(f\"Initial solution: gamma={best_gamma}, n_components={best_n_components}, acc={best_acc:.4f}\")\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Generate neighbor solutions\n",
        "    candidate_gamma = best_gamma + random.choice([-0.5, 0.5])\n",
        "    candidate_n_components = best_n_components + random.choice([-50, 50])\n",
        "\n",
        "    # Bounds\n",
        "    candidate_gamma = max(0.1, min(5, candidate_gamma))\n",
        "    candidate_n_components = max(50, min(500, candidate_n_components))\n",
        "\n",
        "    # Check tabu list\n",
        "    if (candidate_gamma, candidate_n_components) in tabu_list:\n",
        "        continue\n",
        "\n",
        "    # Evaluate candidate\n",
        "    acc = evaluate_solution(candidate_gamma, candidate_n_components)\n",
        "    print(f\"Iteration {iteration+1}: gamma={candidate_gamma}, n_components={candidate_n_components}, acc={acc:.4f}\")\n",
        "\n",
        "    # Update best\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_gamma = candidate_gamma\n",
        "        best_n_components = candidate_n_components\n",
        "\n",
        "    # Update tabu list\n",
        "    tabu_list.append((candidate_gamma, candidate_n_components))\n",
        "    if len(tabu_list) > tabu_size:\n",
        "        tabu_list.pop(0)\n",
        "\n",
        "print(f\"Optimized solution: gamma={best_gamma}, n_components={best_n_components}, acc={best_acc:.4f}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# Step 5: Final Evaluation\n",
        "# ================================\n",
        "rbf_feature = RBFSampler(gamma=best_gamma, n_components=best_n_components, random_state=42)\n",
        "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
        "X_test_rbf = rbf_feature.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train_rbf, y_train)\n",
        "y_pred = clf.predict(X_test_rbf)\n",
        "\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: minisom in /usr/local/lib/python3.12/dist-packages (2.3.5)\n",
            "                                                 url        type\n",
            "0                               http://kitegacc.net/    phishing\n",
            "1  https://www.electronichouse.com/article/ps3_ad...  legitimate\n",
            "2      https://www.linkedin.com/in/larrymartinkimpel  legitimate\n",
            "3  https://www.kansascity.com/2011/03/05/2700249/...  legitimate\n",
            "4        https://www.en.wikipedia.org/wiki/Dem_Bones  legitimate\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208876 entries, 0 to 208875\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   url     208876 non-null  object\n",
            " 1   type    208876 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.2+ MB\n",
            "None\n",
            "Baseline Accuracy: 0.9795815779394867\n",
            "Initial solution: gamma=1, n_components=100, acc=0.9796\n",
            "Iteration 1: gamma=1.5, n_components=150, acc=0.9803\n",
            "Iteration 2: gamma=2.0, n_components=200, acc=0.9800\n",
            "Iteration 3: gamma=1.0, n_components=100, acc=0.9796\n",
            "Iteration 5: gamma=1.0, n_components=200, acc=0.9800\n",
            "Iteration 6: gamma=2.0, n_components=100, acc=0.9799\n",
            "Optimized solution: gamma=1.5, n_components=150, acc=0.9803\n",
            "\n",
            "Final Model Performance:\n",
            "Accuracy: 0.9802757564151666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  legitimate       0.97      0.99      0.98     20862\n",
            "    phishing       0.99      0.97      0.98     20914\n",
            "\n",
            "    accuracy                           0.98     41776\n",
            "   macro avg       0.98      0.98      0.98     41776\n",
            "weighted avg       0.98      0.98      0.98     41776\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Setup\n",
        "# ================================\n",
        "!pip install minisom -q\n",
        "\n",
        "import os, re, math, random, numpy as np, pandas as pd, tensorflow as tf\n",
        "from urllib.parse import urlparse\n",
        "from minisom import MiniSom\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ================================\n",
        "# Load dataset\n",
        "# ================================\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Assignment/URL_dataset_clean_balanced.csv')\n",
        "print(dataset.head())\n",
        "print(dataset.info())\n",
        "\n",
        "# ================================\n",
        "# URL → feature engineering\n",
        "# ================================\n",
        "def extract_url_features(url):\n",
        "    features = {}\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        features['url_length'] = len(url)\n",
        "        features['num_dots'] = url.count('.')\n",
        "        features['has_at_symbol'] = 1 if '@' in url else 0\n",
        "        features['has_double_slash'] = 1 if '//' in url else 0\n",
        "        features['num_dashes'] = url.count('-')\n",
        "        features['num_underscores'] = url.count('_')\n",
        "        features['num_equals'] = url.count('=')\n",
        "        features['num_semicolons'] = url.count(';')\n",
        "        features['num_commas'] = url.count(',')\n",
        "        features['num_quotes'] = url.count(\"'\") + url.count('\"')\n",
        "        features['num_less_than'] = url.count('<')\n",
        "        features['num_greater_than'] = url.count('>')\n",
        "        features['num_braces'] = url.count('{') + url.count('}')\n",
        "        features['num_brackets'] = url.count('[') + url.count(']')\n",
        "        features['num_parentheses'] = url.count('(') + url.count(')')\n",
        "        features['num_hashes'] = url.count('#')\n",
        "        features['num_exclamations'] = url.count('!')\n",
        "        features['num_dollars'] = url.count('$')\n",
        "        features['num_spaces'] = url.count(' ')\n",
        "        features['num_slashes'] = url.count('/')\n",
        "        features['num_questions'] = url.count('?')\n",
        "        features['num_and'] = url.count('&')\n",
        "        features['num_or'] = url.count('|')\n",
        "        features['num_tilde'] = url.count('~')\n",
        "        features['num_http'] = url.count('http') + url.count('https')\n",
        "        features['num_www'] = url.count('www')\n",
        "        host = parsed_url.hostname\n",
        "        features['num_subdomains'] = len(host.split('.')) - 2 if host else 0\n",
        "        features['path_length'] = len(parsed_url.path)\n",
        "        features['query_length'] = len(parsed_url.query)\n",
        "        features['fragment_length'] = len(parsed_url.fragment)\n",
        "        ip_re = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
        "        features['has_ip_address'] = 1 if (host and re.match(ip_re, host)) else 0\n",
        "    except Exception:\n",
        "        # robust fallback\n",
        "        features = {k:0 for k in [\n",
        "            'url_length','num_dots','has_at_symbol','has_double_slash','num_dashes','num_underscores',\n",
        "            'num_equals','num_semicolons','num_commas','num_quotes','num_less_than','num_greater_than',\n",
        "            'num_braces','num_brackets','num_parentheses','num_hashes','num_exclamations','num_dollars',\n",
        "            'num_spaces','num_slashes','num_questions','num_and','num_or','num_tilde','num_http',\n",
        "            'num_www','num_subdomains','path_length','query_length','fragment_length','has_ip_address'\n",
        "        ]}\n",
        "    return pd.Series(features)\n",
        "\n",
        "features_df = dataset['url'].apply(extract_url_features)\n",
        "\n",
        "# Labels → 0/1\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(dataset['type'])  # e.g., phishing=1, legitimate=0 (depends on order)\n",
        "\n",
        "# Scale\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(features_df.values.astype(np.float32))\n",
        "\n",
        "# ================================\n",
        "# Train/Test split (then fit unsup. models on train to avoid leakage)\n",
        "# ================================\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# SOM-RMO (Table 8 settings)\n",
        "# SOM grid 10x10 (100 neurons), lr=0.5, radius=5, iters=1000, Gaussian\n",
        "# We'll train SOM on TRAIN ONLY; then map train/test using the learned weights.\n",
        "# RMO: we influence SOM updates toward a \"best\" template and add stochastic exploration.\n",
        "# ================================\n",
        "class RMOSOM:\n",
        "    def __init__(self, n_neurons=100, lr=0.5, radius=5.0, rmo_beta=0.5, rmo_alpha=0.8, rmo_iters=1000):\n",
        "        self.n_neurons = n_neurons\n",
        "        self.lr0 = lr\n",
        "        self.radius0 = radius\n",
        "        self.rmo_beta = rmo_beta  # toward best\n",
        "        self.rmo_alpha = rmo_alpha  # exploration / toward data\n",
        "        self.rmo_iters = rmo_iters\n",
        "        self.weights_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        X = X.astype(np.float32)\n",
        "        n_features = X.shape[1]\n",
        "        # Random init\n",
        "        w = np.random.rand(self.n_neurons, n_features).astype(np.float32)\n",
        "        best_w = w.copy()\n",
        "\n",
        "        for t in range(self.rmo_iters):\n",
        "            # exp decay (common in SOM)\n",
        "            lr_t = self.lr0 * math.exp(-t / self.rmo_iters)\n",
        "            rad_t = self.radius0 * math.exp(-t / self.rmo_iters) + 1e-6\n",
        "\n",
        "            # random sample\n",
        "            idx = np.random.randint(0, X.shape[0])\n",
        "            x = X[idx]\n",
        "\n",
        "            # BMU\n",
        "            dists = np.linalg.norm(w - x, axis=1)\n",
        "            bmu = np.argmin(dists)\n",
        "            bmu_w = w[bmu]\n",
        "\n",
        "            # Update all neurons (Gaussian neighborhood)\n",
        "            for i in range(self.n_neurons):\n",
        "                dist_i = np.linalg.norm(w[i] - bmu_w)\n",
        "                h = math.exp(-(dist_i**2) / (2 * (rad_t**2)))\n",
        "\n",
        "                # RMO-like movement: toward \"best\" template and toward data point\n",
        "                rmo_move = (\n",
        "                    self.rmo_beta * np.random.rand() * (best_w[i] - w[i]) +\n",
        "                    self.rmo_alpha * np.random.rand() * (x - w[i])\n",
        "                )\n",
        "                w[i] = w[i] + lr_t * h * rmo_move\n",
        "\n",
        "            # Simple \"best\" template refresh (proxy for fitness-improving template)\n",
        "            # In a full RMO, you'd evaluate a fitness and keep the best. Here we periodically snapshot.\n",
        "            if (t+1) % 25 == 0:\n",
        "                best_w = w.copy()\n",
        "\n",
        "        self.weights_ = w\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Map each vector to its BMU weight vector (same dimensionality).\"\"\"\n",
        "        X = X.astype(np.float32)\n",
        "        out = np.zeros_like(X)\n",
        "        for i, x in enumerate(X):\n",
        "            dists = np.linalg.norm(self.weights_ - x, axis=1)\n",
        "            bmu = np.argmin(dists)\n",
        "            out[i] = self.weights_[bmu]\n",
        "        return out\n",
        "\n",
        "# Fit SOM-RMO on training, then transform train/test\n",
        "som = RMOSOM(n_neurons=10*10, lr=0.5, radius=5.0, rmo_beta=0.5, rmo_alpha=0.8, rmo_iters=1000)\n",
        "som.fit(X_train_raw)\n",
        "X_train_som = som.transform(X_train_raw)\n",
        "X_test_som  = som.transform(X_test_raw)\n",
        "print(\"SOM-RMO features:\", X_train_som.shape, X_test_som.shape)\n",
        "\n",
        "# ================================\n",
        "# RBFN (TensorFlow) with K-means centers (Table 8)\n",
        "# Centers=100, Gaussian RBF, SGD lr=0.01, momentum=0.9, Epochs=500\n",
        "# ================================\n",
        "n_centers = 100\n",
        "kmeans = KMeans(n_clusters=n_centers, random_state=42, n_init='auto')\n",
        "kmeans.fit(X_train_som)\n",
        "centers = kmeans.cluster_centers_.astype(np.float32)\n",
        "\n",
        "# Beta init from inter-center spacing\n",
        "def init_beta_from_centers(centers):\n",
        "    # median pairwise distance heuristic → sigma\n",
        "    from sklearn.metrics import pairwise_distances\n",
        "    D = pairwise_distances(centers, centers)\n",
        "    sigma = np.median(D[D>0])  # avoid zeros on diagonal\n",
        "    sigma = float(max(sigma, 1e-3))\n",
        "    beta = 1.0 / (2.0 * sigma * sigma)\n",
        "    return beta\n",
        "\n",
        "beta_init = init_beta_from_centers(centers)\n",
        "\n",
        "class RBFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, centers, beta):\n",
        "        super().__init__()\n",
        "        self.centers = tf.constant(centers, dtype=tf.float32)  # fixed centers\n",
        "        # beta is trainable per Table 8? We'll keep global beta trainable in final model.\n",
        "        self.beta = tf.Variable(initial_value=beta, trainable=True, dtype=tf.float32, name=\"beta\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs: [batch, d]\n",
        "        # centers: [C, d]\n",
        "        # compute ||x - c||^2\n",
        "        x_exp = tf.expand_dims(inputs, axis=1)      # [batch, 1, d]\n",
        "        c_exp = tf.expand_dims(self.centers, axis=0)# [1, C, d]\n",
        "        diff = x_exp - c_exp                        # [batch, C, d]\n",
        "        l2 = tf.reduce_sum(tf.square(diff), axis=-1)  # [batch, C]\n",
        "        return tf.exp(-self.beta * l2)              # [batch, C]\n",
        "\n",
        "def build_rbfn_model(input_dim, centers, beta, l2=0.0):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,), name=\"rbf_input\")\n",
        "    rbf = RBFLayer(centers, beta)(inputs)  # [batch, C]\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(l2))(rbf)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "input_dim = X_train_som.shape[1]\n",
        "\n",
        "# ================================\n",
        "# Tabu Search (Table 8)\n",
        "# - list size=50\n",
        "# - iterations=100 (stop early after 10 non-improving)\n",
        "# - aspiration=True\n",
        "# - initial temperature=100, exponential cooling\n",
        "# - mutation rate=0.1, crossover rate=0.7\n",
        "# We optimize: beta_scale (multiplies beta_init), and l2 (output layer L2).\n",
        "# ================================\n",
        "tabu_list = []\n",
        "TABU_SIZE = 50\n",
        "MAX_ITERS = 10 #----------------------------------------------------change dy from 100-------------------------------------------\n",
        "NO_IMPROVE_LIMIT = 10\n",
        "ASPIRATION = True\n",
        "TEMP = 100.0\n",
        "COOL = 0.95\n",
        "MUT_RATE = 0.1\n",
        "CROSS_RATE = 0.7\n",
        "\n",
        "# Search spaces\n",
        "BETA_SCALE_MIN, BETA_SCALE_MAX = 0.1, 10.0\n",
        "L2_MIN, L2_MAX = 0.0, 1e-2\n",
        "\n",
        "def clamp(v, lo, hi): return max(lo, min(hi, v))\n",
        "\n",
        "def proxy_eval(beta_scale, l2):\n",
        "    \"\"\"Quick proxy evaluation: train a small model for few epochs and return accuracy.\"\"\"\n",
        "    beta = float(beta_init * beta_scale)\n",
        "    model = build_rbfn_model(input_dim, centers, beta, l2=l2)\n",
        "    # fewer epochs for speed during search\n",
        "    history = model.fit(X_train_som, y_train, epochs=15, batch_size=256, verbose=0,\n",
        "                        validation_split=0.1, shuffle=True)\n",
        "    # Evaluate on held-out test\n",
        "    preds = (model.predict(X_test_som, verbose=0) > 0.5).astype(\"int32\").ravel()\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    return acc\n",
        "\n",
        "# Initialize two random candidates to enable crossover\n",
        "def random_candidate():\n",
        "    return (\n",
        "        random.uniform(BETA_SCALE_MIN, BETA_SCALE_MAX),\n",
        "        random.uniform(L2_MIN, L2_MAX),\n",
        "    )\n",
        "\n",
        "cand_a = (1.0, 0.0)  # start from table defaults (beta_scale=1, l2=0)\n",
        "best_beta_scale, best_l2 = cand_a\n",
        "best_acc = proxy_eval(*cand_a)\n",
        "tabu_list.append(cand_a)\n",
        "no_improve = 0\n",
        "\n",
        "# second candidate\n",
        "cand_b = random_candidate()\n",
        "acc_b = proxy_eval(*cand_b)\n",
        "if acc_b > best_acc:\n",
        "    best_acc, best_beta_scale, best_l2 = acc_b, cand_b[0], cand_b[1]\n",
        "tabu_list.append(cand_b)\n",
        "\n",
        "print(f\"[TS] init: beta_scale={best_beta_scale:.4f}, l2={best_l2:.6f}, acc={best_acc:.4f}\")\n",
        "\n",
        "for it in range(1, MAX_ITERS+1):\n",
        "    # Crossover\n",
        "    if random.random() < CROSS_RATE:\n",
        "        parent1, parent2 = random.choice(tabu_list), random.choice(tabu_list)\n",
        "        child_beta = 0.5*(parent1[0] + parent2[0])\n",
        "        child_l2   = 0.5*(parent1[1] + parent2[1])\n",
        "    else:\n",
        "        # local neighbor around best\n",
        "        child_beta = np.random.normal(loc=best_beta_scale, scale=0.2)\n",
        "        child_l2   = np.random.normal(loc=best_l2, scale=1e-3)\n",
        "\n",
        "    # Mutation\n",
        "    if random.random() < MUT_RATE:\n",
        "        child_beta += np.random.normal(scale=0.1)\n",
        "    if random.random() < MUT_RATE:\n",
        "        child_l2   += np.random.normal(scale=5e-4)\n",
        "\n",
        "    # clamp\n",
        "    child_beta = clamp(child_beta, BETA_SCALE_MIN, BETA_SCALE_MAX)\n",
        "    child_l2   = clamp(child_l2, L2_MIN, L2_MAX)\n",
        "\n",
        "    # Tabu check (rounded key to reduce duplicates)\n",
        "    key = (round(child_beta, 4), round(child_l2, 6))\n",
        "    if key in [(round(b,4), round(l,6)) for (b,l) in tabu_list] and not ASPIRATION:\n",
        "        # skip if tabu and no aspiration\n",
        "        TEMP *= COOL\n",
        "        continue\n",
        "\n",
        "    # Evaluate\n",
        "    acc = proxy_eval(child_beta, child_l2)\n",
        "\n",
        "    # Aspiration: allow tabu if better than global best\n",
        "    tabu_violation = key in [(round(b,4), round(l,6)) for (b,l) in tabu_list]\n",
        "    if (acc > best_acc) or (tabu_violation and ASPIRATION):\n",
        "        best_acc = acc\n",
        "        best_beta_scale, best_l2 = child_beta, child_l2\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        # SA-like acceptance with temperature\n",
        "        delta = best_acc - acc\n",
        "        accept_prob = math.exp(-max(0.0, delta) / max(1e-6, TEMP))\n",
        "        if random.random() < accept_prob:\n",
        "            # accept move (doesn't change best, but explores region)\n",
        "            no_improve += 1\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "    # Update tabu\n",
        "    tabu_list.append((child_beta, child_l2))\n",
        "    if len(tabu_list) > TABU_SIZE:\n",
        "        tabu_list.pop(0)\n",
        "\n",
        "    print(f\"[TS] iter {it:03d}: beta_scale={child_beta:.4f}, l2={child_l2:.6f}, acc={acc:.4f}, best={best_acc:.4f}, T={TEMP:.2f}\")\n",
        "    TEMP *= COOL\n",
        "    if no_improve >= NO_IMPROVE_LIMIT:\n",
        "        print(f\"[TS] Stopping early after {NO_IMPROVE_LIMIT} non-improving iterations.\")\n",
        "        break\n",
        "\n",
        "print(f\"[TS] best: beta_scale={best_beta_scale:.4f}, l2={best_l2:.6f}, proxy_acc={best_acc:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# Final Training (Table 8 epochs=500) with best TS params\n",
        "# ================================\n",
        "beta_final = float(beta_init * best_beta_scale)\n",
        "final_model = build_rbfn_model(input_dim, centers, beta_final, l2=best_l2)\n",
        "final_model.summary()\n",
        "\n",
        "history = final_model.fit(\n",
        "    X_train_som, y_train,\n",
        "    epochs=50, batch_size=256, verbose=0,  #-------------------------------------------------epoches change from 500 -----------------------\n",
        "    validation_split=0.1, shuffle=True\n",
        ")\n",
        "\n",
        "y_pred_prob = final_model.predict(X_test_som, verbose=0).ravel()\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=list(le.classes_)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1w4jc3Qay7Xd",
        "outputId": "ceaf260e-1133-433d-eabf-31cac9122fff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 url        type\n",
            "0                               http://kitegacc.net/    phishing\n",
            "1  https://www.electronichouse.com/article/ps3_ad...  legitimate\n",
            "2      https://www.linkedin.com/in/larrymartinkimpel  legitimate\n",
            "3  https://www.kansascity.com/2011/03/05/2700249/...  legitimate\n",
            "4        https://www.en.wikipedia.org/wiki/Dem_Bones  legitimate\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208876 entries, 0 to 208875\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   url     208876 non-null  object\n",
            " 1   type    208876 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.2+ MB\n",
            "None\n",
            "SOM-RMO features: (167100, 31) (41776, 31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (39) found smaller than n_clusters (100). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TS] init: beta_scale=1.0000, l2=0.000000, acc=0.9257\n",
            "[TS] iter 001: beta_scale=1.0000, l2=0.000000, acc=0.9257, best=0.9257, T=100.00\n",
            "[TS] iter 002: beta_scale=1.0898, l2=0.000000, acc=0.9257, best=0.9257, T=95.00\n",
            "[TS] iter 003: beta_scale=1.0449, l2=0.000062, acc=0.9257, best=0.9257, T=90.25\n",
            "[TS] iter 004: beta_scale=1.1011, l2=0.003708, acc=0.9259, best=0.9259, T=85.74\n",
            "[TS] iter 005: beta_scale=1.0000, l2=0.000000, acc=0.9257, best=0.9257, T=81.45\n",
            "[TS] iter 006: beta_scale=1.0673, l2=0.000031, acc=0.9257, best=0.9257, T=77.38\n",
            "[TS] iter 007: beta_scale=0.6798, l2=0.000000, acc=0.9257, best=0.9257, T=73.51\n",
            "[TS] iter 008: beta_scale=1.0673, l2=0.000031, acc=0.9257, best=0.9257, T=69.83\n",
            "[TS] iter 009: beta_scale=1.0561, l2=0.000047, acc=0.9257, best=0.9257, T=66.34\n",
            "[TS] iter 010: beta_scale=1.0483, l2=0.000047, acc=0.9257, best=0.9257, T=63.02\n",
            "[TS] best: beta_scale=1.0673, l2=0.000031, proxy_acc=0.9257\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_24\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_24\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rbf_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rbf_layer_24 (\u001b[38;5;33mRBFLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rbf_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rbf_layer_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RBFLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101\u001b[0m (404.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> (404.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101\u001b[0m (404.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> (404.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Performance:\n",
            "Accuracy: 0.9326646878590579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  legitimate       0.89      0.99      0.94     20888\n",
            "    phishing       0.99      0.88      0.93     20888\n",
            "\n",
            "    accuracy                           0.93     41776\n",
            "   macro avg       0.94      0.93      0.93     41776\n",
            "weighted avg       0.94      0.93      0.93     41776\n",
            "\n"
          ]
        }
      ]
    }
  ]
}