{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR4Y0h7bUy3+W1lnqBYXSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juwetta/DLI_Group-B/blob/main/DLI_Malicious_URL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0TmHpBRdt1V",
        "outputId": "5dc461f3-cdc4-4948-ec05-17523039a7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import imporant libraries"
      ],
      "metadata": {
        "id": "W661yBy9oQiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import glob\n",
        "import scipy.sparse\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2rPIABucoPoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing to folder"
      ],
      "metadata": {
        "id": "AzFwtL3ZoWsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/DLI Group B/url_svmlight'\n",
        "\n",
        "svm_files = glob.glob(os.path.join(folder_path, \"*.svm\"))\n",
        "print(f\"Found {len(svm_files)} SVM files in: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLsnaAxMobYW",
        "outputId": "ad10ed31-f327-466a-a829-77c585f09b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 SVM files in: /content/drive/My Drive/DLI Group B/url_svmlight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of the output, \"shape\" refers to the dimensions of the data structure (like a NumPy array or a SciPy sparse matrix).\n",
        "\n",
        "For a 2D structure like combined_X, the shape (2396130, 3231961) means it has 2,396,130 rows and 3,231,961 columns. In this dataset, the rows represent the samples (e.g., URLs), and the columns represent the features.\n",
        "For a 1D structure like combined_y, the shape (2396130,) means it has 2,396,130 elements. This corresponds to the labels for each of the samples in combined_X.\n",
        "So, the shape tells you how many samples you have and how many features or labels are associated with each sample."
      ],
      "metadata": {
        "id": "EPR2aZsXJWN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read SVM file and store dataset\n"
      ],
      "metadata": {
        "id": "MKkrToETooYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the different SVM files have varying numbers of features, causing an error when trying to combine them. I'll add a step to determine the total number of features across all files and then load each file with that consistent number of features."
      ],
      "metadata": {
        "id": "G1tzLDporKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 0\n",
        "\n",
        "for file_path in svm_files:\n",
        "  try:\n",
        "    X, _ = load_svmlight_file(file_path)\n",
        "    if X.shape[1] > max_features:\n",
        "      max_features = X.shape[1]\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "\n",
        "print(f\"Maximum number of features found: {max_features}\") #146.758s used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v3O3-CsqtRQ",
        "outputId": "95c08d1f-33ed-422c-e2b1-4d9f9dd07352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of features found: 3231961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_X = []\n",
        "all_y = []\n",
        "max_features = 3231961\n",
        "try:\n",
        "    print(\"\\nLoading and combining data...\")\n",
        "\n",
        "    # Load and combine data in a single pass, specifying the number of features\n",
        "    for file_path in svm_files:\n",
        "        try:\n",
        "            X, y = load_svmlight_file(file_path, n_features=max_features)\n",
        "            all_X.append(X)\n",
        "            all_y.append(y)\n",
        "            print(f\"{os.path.basename(file_path)}\", end=\"| \")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "    if all_X and all_y:\n",
        "        # Vertically stack the sparse feature matrices\n",
        "        combined_X = scipy.sparse.vstack(all_X)\n",
        "        # Concatenate the label arrays\n",
        "        combined_y = np.concatenate(all_y)\n",
        "\n",
        "        print(\"\\nSuccessfully combined data from all files.\")\n",
        "        print(f\"Shape of combined data (X): {combined_X.shape}\")\n",
        "        print(f\"Shape of combined labels (y): {combined_y.shape}\")\n",
        "    else:\n",
        "        print(\"\\nNo data was loaded from the SVM files.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Folder not found at: {folder_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\") #154.318s used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIVvCQxf9EAH",
        "outputId": "16a97e66-2812-4791-a68c-65c655549e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading and combining data...\n",
            "\n",
            "Successfully combined data from all files.\n",
            "Shape of combined data (X): (2396130, 3231961)\n",
            "Shape of combined labels (y): (2396130,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the indexes of real-valued features"
      ],
      "metadata": {
        "id": "_YDHTWMvpDjk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad19fa23",
        "outputId": "ae7170f5-f9df-4fa0-af80-a9dc9fe433c6"
      },
      "source": [
        "import os\n",
        "\n",
        "feature_types_path = '/content/drive/My Drive/DLI Group B/url_svmlight/FeatureTypes'\n",
        "real_valued_feature_indices = set()\n",
        "\n",
        "try:\n",
        "    with open(feature_types_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Assuming each line in FeatureTypes is a feature index\n",
        "            try:\n",
        "                index = int(line.strip())\n",
        "                real_valued_feature_indices.add(index)\n",
        "            except ValueError:\n",
        "                # Handle potential non-integer lines in the file\n",
        "                print(f\"Skipping non-integer line in FeatureTypes: {line.strip()}\")\n",
        "\n",
        "    print(f\"Identified {len(real_valued_feature_indices)} real-valued feature indices.\")\n",
        "    # print(\"First 10 real-valued feature indices:\", list(real_valued_feature_indices)[:10]) # Optional: print a few indices\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"FeatureTypes file not found at: {feature_types_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading FeatureTypes: {e}\")\n",
        "\n",
        "# Now you have the set of real-valued feature indices and can use it\n",
        "# For example, you could filter your data or analyze these specific features."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 64 real-valued feature indices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Briefly explore the dataset"
      ],
      "metadata": {
        "id": "3d8LW7gkpK-3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e46d2c3",
        "outputId": "a8d7fdb7-e28f-4317-d1e9-87b04e6bcad6"
      },
      "source": [
        "# Select the first few rows to inspect\n",
        "num_rows_to_inspect = 5\n",
        "sample_rows = combined_X[:num_rows_to_inspect]\n",
        "\n",
        "print(f\"Values of real-valued features in the first {num_rows_to_inspect} rows:\")\n",
        "\n",
        "# Iterate through the selected rows\n",
        "for i in range(sample_rows.shape[0]):\n",
        "    print(f\"\\nRow {i+1}:\")\n",
        "    # Iterate through the real-valued feature indices\n",
        "    for feature_index in sorted(list(real_valued_feature_indices)): # Sorting for consistent output\n",
        "        # Check if the feature exists in the current row (i.e., it's non-zero)\n",
        "\n",
        "        if feature_index in sample_rows[i].indices:\n",
        "            # Get the index within the non-zero elements\n",
        "            data_index = np.where(sample_rows[i].indices == feature_index)[0][0]\n",
        "            # Get the value of the feature\n",
        "            feature_value = sample_rows[i].data[data_index]\n",
        "            print(f\"  Feature {feature_index}: {feature_value}\")\n",
        "        # If the feature index is not in sample_rows[i].indices, its value is 0 in the sparse matrix,\n",
        "        # so we don't need to explicitly print 0 unless we want to see all real-valued features\n",
        "        # even if their value is 0 for that sample. Let's only print non-zero real-valued features."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of real-valued features in the first 5 rows:\n",
            "\n",
            "Row 1:\n",
            "  Feature 4: 0.124138\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.749633\n",
            "  Feature 17: 0.843029\n",
            "  Feature 18: 0.197344\n",
            "  Feature 21: 0.142857\n",
            "  Feature 22: 0.142857\n",
            "  Feature 55: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 2:\n",
            "  Feature 4: 0.103448\n",
            "  Feature 5: 0.176471\n",
            "  Feature 16: 0.72266\n",
            "  Feature 17: 0.836498\n",
            "  Feature 18: 0.6189\n",
            "  Feature 21: 0.0119048\n",
            "  Feature 23: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 126: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 3:\n",
            "  Feature 4: 0.144828\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.760482\n",
            "  Feature 17: 0.820882\n",
            "  Feature 18: 0.150678\n",
            "  Feature 21: 0.142857\n",
            "  Feature 23: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 4:\n",
            "  Feature 4: 0.0896552\n",
            "  Feature 5: 0.176471\n",
            "  Feature 21: 0.0238095\n",
            "  Feature 23: 1.0\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 5:\n",
            "  Feature 4: 0.131034\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.830283\n",
            "  Feature 17: 0.83965\n",
            "  Feature 18: 0.583194\n",
            "  Feature 19: 1.0\n",
            "  Feature 21: 0.00595238\n",
            "  Feature 22: 0.00595238\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 132: 1.0\n",
            "  Feature 138: 1.0\n",
            "  Feature 140: 1.0\n",
            "  Feature 142: 1.0\n",
            "  Feature 144: 1.0\n",
            "  Feature 146: 1.0\n",
            "  Feature 148: 1.0\n"
          ]
        }
      ]
    }
  ]
}