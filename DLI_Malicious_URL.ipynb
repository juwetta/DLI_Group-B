{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdFMav54FEFV5vIVVI5HnQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juwetta/DLI_Group-B/blob/main/DLI_Malicious_URL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0TmHpBRdt1V",
        "outputId": "cfe1f8d1-4024-48ce-ddee-76c269b1f24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import imporant libraries"
      ],
      "metadata": {
        "id": "W661yBy9oQiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import glob\n",
        "import scipy.sparse\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2rPIABucoPoQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[code below is used for lower the size of dataset, since the full dataset can used up all the RAM just to storing them]"
      ],
      "metadata": {
        "id": "tBTgFy_JS4WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source folder path\n",
        "source_folder = '/content/drive/My Drive/DLI Group B/url_svmlight'\n",
        "\n",
        "# Define the destination folder path\n",
        "destination_folder = '/content/drive/My Drive/DLI Group B/url_dataset'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# List of files to copy (Day0.svm to Day60.svm and FeatureTypes)\n",
        "files_to_copy = [f'Day{i}.svm' for i in range(61)] + ['FeatureTypes']\n",
        "\n",
        "print(f\"Copying files to: {destination_folder}\")\n",
        "\n",
        "# Copy the specified files\n",
        "for file_name in files_to_copy:\n",
        "    source_file_path = os.path.join(source_folder, file_name)\n",
        "    destination_file_path = os.path.join(destination_folder, file_name)\n",
        "    try:\n",
        "        shutil.copy2(source_file_path, destination_file_path)\n",
        "        print(f\"Copied: {file_name}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: File not found - {file_name}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying file {file_name}: {e}\")\n",
        "\n",
        "print(\"File copying process completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU_Rvf6xR39n",
        "outputId": "292da051-a9ee-4597-dfd7-b99f9ff4e583"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying files to: /content/drive/My Drive/DLI Group B/url_dataset\n",
            "Copied: Day0.svm\n",
            "Copied: Day1.svm\n",
            "Copied: Day2.svm\n",
            "Copied: Day3.svm\n",
            "Copied: Day4.svm\n",
            "Copied: Day5.svm\n",
            "Copied: Day6.svm\n",
            "Copied: Day7.svm\n",
            "Copied: Day8.svm\n",
            "Copied: Day9.svm\n",
            "Copied: Day10.svm\n",
            "Copied: Day11.svm\n",
            "Copied: Day12.svm\n",
            "Copied: Day13.svm\n",
            "Copied: Day14.svm\n",
            "Copied: Day15.svm\n",
            "Copied: Day16.svm\n",
            "Copied: Day17.svm\n",
            "Copied: Day18.svm\n",
            "Copied: Day19.svm\n",
            "Copied: Day20.svm\n",
            "Copied: Day21.svm\n",
            "Copied: Day22.svm\n",
            "Copied: Day23.svm\n",
            "Copied: Day24.svm\n",
            "Copied: Day25.svm\n",
            "Copied: Day26.svm\n",
            "Copied: Day27.svm\n",
            "Copied: Day28.svm\n",
            "Copied: Day29.svm\n",
            "Copied: Day30.svm\n",
            "Copied: Day31.svm\n",
            "Copied: Day32.svm\n",
            "Copied: Day33.svm\n",
            "Copied: Day34.svm\n",
            "Copied: Day35.svm\n",
            "Copied: Day36.svm\n",
            "Copied: Day37.svm\n",
            "Copied: Day38.svm\n",
            "Copied: Day39.svm\n",
            "Copied: Day40.svm\n",
            "Copied: Day41.svm\n",
            "Copied: Day42.svm\n",
            "Copied: Day43.svm\n",
            "Copied: Day44.svm\n",
            "Copied: Day45.svm\n",
            "Copied: Day46.svm\n",
            "Copied: Day47.svm\n",
            "Copied: Day48.svm\n",
            "Copied: Day49.svm\n",
            "Copied: Day50.svm\n",
            "Copied: Day51.svm\n",
            "Copied: Day52.svm\n",
            "Copied: Day53.svm\n",
            "Copied: Day54.svm\n",
            "Copied: Day55.svm\n",
            "Copied: Day56.svm\n",
            "Copied: Day57.svm\n",
            "Copied: Day58.svm\n",
            "Copied: Day59.svm\n",
            "Copied: Day60.svm\n",
            "Copied: FeatureTypes\n",
            "File copying process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing to folder"
      ],
      "metadata": {
        "id": "AzFwtL3ZoWsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/DLI Group B/url_dataset'\n",
        "\n",
        "svm_files = glob.glob(os.path.join(folder_path, \"*.svm\"))\n",
        "print(f\"Found {len(svm_files)} SVM files in: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLsnaAxMobYW",
        "outputId": "85ca975f-606e-4d31-b280-9547146a38d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 61 SVM files in: /content/drive/My Drive/DLI Group B/url_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of the output, \"shape\" refers to the dimensions of the data structure (like a NumPy array or a SciPy sparse matrix).\n",
        "\n",
        "For a 2D structure like combined_X, the shape (2396130, 3231961) means it has 2,396,130 rows and 3,231,961 columns. In this dataset, the rows represent the samples (e.g., URLs), and the columns represent the features.\n",
        "For a 1D structure like combined_y, the shape (2396130,) means it has 2,396,130 elements. This corresponds to the labels for each of the samples in combined_X.\n",
        "So, the shape tells you how many samples you have and how many features or labels are associated with each sample."
      ],
      "metadata": {
        "id": "EPR2aZsXJWN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read SVM file and store dataset\n"
      ],
      "metadata": {
        "id": "MKkrToETooYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the different SVM files have varying numbers of features, causing an error when trying to combine them. I'll add a step to determine the total number of features across all files and then load each file with that consistent number of features."
      ],
      "metadata": {
        "id": "G1tzLDporKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max_features = 0\n",
        "\n",
        "# for file_path in svm_files:\n",
        "#   try:\n",
        "#     X, _ = load_svmlight_file(file_path)\n",
        "#     if X.shape[1] > max_features:\n",
        "#       max_features = X.shape[1]\n",
        "\n",
        "#   except Exception as e:\n",
        "#     print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "\n",
        "# print(f\"Maximum number of features found: {max_features}\") #74.777s used\n",
        "max_features = 3231961\n",
        "print(f\"Maximum number of features found: {max_features}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v3O3-CsqtRQ",
        "outputId": "c960ceda-68ee-462e-94ac-96b7dec28651"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of features found: 3231961\n",
            "Maximum number of features found: 3231961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_X = []\n",
        "all_y = []\n",
        "max_features = 3231961\n",
        "try:\n",
        "    print(\"\\nLoading and combining data...\")\n",
        "\n",
        "    # Load and combine data in a single pass, specifying the number of features\n",
        "    for file_path in svm_files:\n",
        "        try:\n",
        "            X, y = load_svmlight_file(file_path, n_features=max_features)\n",
        "            all_X.append(X)\n",
        "            all_y.append(y)\n",
        "            print(f\"{os.path.basename(file_path)}\", end=\"| \")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "    if all_X and all_y:\n",
        "        # Vertically stack the sparse feature matrices\n",
        "        combined_X = scipy.sparse.vstack(all_X)\n",
        "        # Concatenate the label arrays\n",
        "        combined_y = np.concatenate(all_y)\n",
        "\n",
        "        print(\"\\nSuccessfully combined data from all files.\")\n",
        "        print(f\"Shape of combined data (X): {combined_X.shape}\")\n",
        "        print(f\"Shape of combined labels (y): {combined_y.shape}\")\n",
        "    else:\n",
        "        print(\"\\nNo data was loaded from the SVM files.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Folder not found at: {folder_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\") #75.54s used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIVvCQxf9EAH",
        "outputId": "a2565563-f8e8-422e-9dd7-57b66cf2079d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading and combining data...\n",
            "Day0.svm| Day1.svm| Day2.svm| Day3.svm| Day4.svm| Day5.svm| Day6.svm| Day7.svm| Day8.svm| Day9.svm| Day10.svm| Day11.svm| Day12.svm| Day13.svm| Day14.svm| Day15.svm| Day16.svm| Day17.svm| Day18.svm| Day19.svm| Day20.svm| Day21.svm| Day22.svm| Day23.svm| Day24.svm| Day25.svm| Day26.svm| Day27.svm| Day28.svm| Day29.svm| Day30.svm| Day31.svm| Day32.svm| Day33.svm| Day34.svm| Day35.svm| Day36.svm| Day37.svm| Day38.svm| Day39.svm| Day40.svm| Day41.svm| Day42.svm| Day43.svm| Day44.svm| Day45.svm| Day46.svm| Day47.svm| Day48.svm| Day49.svm| Day50.svm| Day51.svm| Day52.svm| Day53.svm| Day54.svm| Day55.svm| Day56.svm| Day57.svm| Day58.svm| Day59.svm| Day60.svm| \n",
            "Successfully combined data from all files.\n",
            "Shape of combined data (X): (1196130, 3231961)\n",
            "Shape of combined labels (y): (1196130,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the indexes of real-valued features"
      ],
      "metadata": {
        "id": "_YDHTWMvpDjk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad19fa23",
        "outputId": "746360e7-5806-4888-91ab-ec15e6677158"
      },
      "source": [
        "import os\n",
        "\n",
        "feature_types_path = '/content/drive/My Drive/DLI Group B/url_dataset/FeatureTypes'\n",
        "real_valued_feature_indices = set()\n",
        "\n",
        "try:\n",
        "    with open(feature_types_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Assuming each line in FeatureTypes is a feature index\n",
        "            try:\n",
        "                index = int(line.strip())\n",
        "                real_valued_feature_indices.add(index)\n",
        "            except ValueError:\n",
        "                # Handle potential non-integer lines in the file\n",
        "                print(f\"Skipping non-integer line in FeatureTypes: {line.strip()}\")\n",
        "\n",
        "    print(f\"Identified {len(real_valued_feature_indices)} real-valued feature indices.\")\n",
        "    # print(\"First 10 real-valued feature indices:\", list(real_valued_feature_indices)[:10]) # Optional: print a few indices\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"FeatureTypes file not found at: {feature_types_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading FeatureTypes: {e}\")\n",
        "\n",
        "# Now you have the set of real-valued feature indices and can use it\n",
        "# For example, you could filter your data or analyze these specific features."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 64 real-valued feature indices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Briefly explore the dataset"
      ],
      "metadata": {
        "id": "3d8LW7gkpK-3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e46d2c3",
        "outputId": "1812d476-afed-4795-e301-70767ff7b508"
      },
      "source": [
        "# Select the first few rows to inspect\n",
        "num_rows_to_inspect = 5\n",
        "sample_rows = combined_X[:num_rows_to_inspect]\n",
        "\n",
        "print(f\"Values of real-valued features in the first {num_rows_to_inspect} rows:\")\n",
        "\n",
        "# Iterate through the selected rows\n",
        "for i in range(sample_rows.shape[0]):\n",
        "    print(f\"\\nRow {i+1}:\")\n",
        "    # Iterate through the real-valued feature indices\n",
        "    for feature_index in sorted(list(real_valued_feature_indices)): # Sorting for consistent output\n",
        "        # Check if the feature exists in the current row (i.e., it's non-zero)\n",
        "\n",
        "        if feature_index in sample_rows[i].indices:\n",
        "            # Get the index within the non-zero elements\n",
        "            data_index = np.where(sample_rows[i].indices == feature_index)[0][0]\n",
        "            # Get the value of the feature\n",
        "            feature_value = sample_rows[i].data[data_index]\n",
        "            print(f\"  Feature {feature_index}: {feature_value}\")\n",
        "        # If the feature index is not in sample_rows[i].indices, its value is 0 in the sparse matrix,\n",
        "        # so we don't need to explicitly print 0 unless we want to see all real-valued features\n",
        "        # even if their value is 0 for that sample. Let's only print non-zero real-valued features."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of real-valued features in the first 5 rows:\n",
            "\n",
            "Row 1:\n",
            "  Feature 4: 0.124138\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.749633\n",
            "  Feature 17: 0.843029\n",
            "  Feature 18: 0.197344\n",
            "  Feature 21: 0.142857\n",
            "  Feature 22: 0.142857\n",
            "  Feature 55: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 2:\n",
            "  Feature 4: 0.103448\n",
            "  Feature 5: 0.176471\n",
            "  Feature 16: 0.72266\n",
            "  Feature 17: 0.836498\n",
            "  Feature 18: 0.6189\n",
            "  Feature 21: 0.0119048\n",
            "  Feature 23: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 126: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 3:\n",
            "  Feature 4: 0.144828\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.760482\n",
            "  Feature 17: 0.820882\n",
            "  Feature 18: 0.150678\n",
            "  Feature 21: 0.142857\n",
            "  Feature 23: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 4:\n",
            "  Feature 4: 0.0896552\n",
            "  Feature 5: 0.176471\n",
            "  Feature 21: 0.0238095\n",
            "  Feature 23: 1.0\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 5:\n",
            "  Feature 4: 0.131034\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.830283\n",
            "  Feature 17: 0.83965\n",
            "  Feature 18: 0.583194\n",
            "  Feature 19: 1.0\n",
            "  Feature 21: 0.00595238\n",
            "  Feature 22: 0.00595238\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 132: 1.0\n",
            "  Feature 138: 1.0\n",
            "  Feature 140: 1.0\n",
            "  Feature 142: 1.0\n",
            "  Feature 144: 1.0\n",
            "  Feature 146: 1.0\n",
            "  Feature 148: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb21fdfb"
      },
      "source": [
        "# Task\n",
        "Balance the classes in the `combined_y` variable of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e12ae549"
      },
      "source": [
        "## Check class distribution\n",
        "\n",
        "### Subtask:\n",
        "Analyze the current distribution of the target variable (`combined_y`) to see how imbalanced the classes are.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed82c52"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and print the counts of each unique class in the `combined_y` array to understand the class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bb1f3a4",
        "outputId": "86b37b64-0010-44e1-89e3-a7f8c786e29a"
      },
      "source": [
        "unique_classes, class_counts = np.unique(combined_y, return_counts=True)\n",
        "\n",
        "print(\"Class distribution in combined_y:\")\n",
        "for class_val, count in zip(unique_classes, class_counts):\n",
        "    print(f\"Class {int(class_val)}: {count}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in combined_y:\n",
            "Class -1: 792438\n",
            "Class 1: 403692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ad112b"
      },
      "source": [
        "## Choose a balancing technique\n",
        "\n",
        "### Subtask:\n",
        "Decide on an appropriate method for balancing the classes, such as oversampling (e.g., SMOTE), undersampling, or a combination.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "562c76ef"
      },
      "source": [
        "## Apply the balancing technique\n",
        "\n",
        "### Subtask:\n",
        "Apply the balancing technique\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadc4dfd"
      },
      "source": [
        "**Reasoning**:\n",
        "To balance the dataset, I will first import the necessary libraries, `SMOTE` and `RandomUnderSampler`. Then, I will apply SMOTE to oversample the minority class, followed by RandomUnderSampler to undersample the majority class, as per the instructions. This will create a more balanced dataset for model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "24022c39",
        "outputId": "0b934584-128b-45cc-b6da-92917b044f1c"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 1. Instantiate SMOTE\n",
        "# Adjust sampling_strategy to 'auto' or a higher value\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# 2. Apply SMOTE to the data\n",
        "X_smote, y_smote = smote.fit_resample(combined_X, combined_y)\n",
        "\n",
        "# 3. Instantiate RandomUnderSampler\n",
        "# Adjust sampling_strategy to 'auto' or 1.0 to balance the classes after SMOTE\n",
        "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# 4. Apply RandomUnderSampler to the SMOTE-resampled data\n",
        "X_resampled, y_resampled = rus.fit_resample(X_smote, y_smote)\n",
        "\n",
        "# Print the shapes of the resampled data to verify\n",
        "print(f\"Shape of X after SMOTE and RandomUnderSampler: {X_resampled.shape}\")\n",
        "print(f\"Shape of y after SMOTE and RandomUnderSampler: {y_resampled.shape}\")\n",
        "\n",
        "# Verify the new class distribution\n",
        "unique_classes_resampled, class_counts_resampled = np.unique(y_resampled, return_counts=True)\n",
        "print(\"\\nClass distribution after resampling:\")\n",
        "for class_val, count in zip(unique_classes_resampled, class_counts_resampled):\n",
        "    print(f\"Class {int(class_val)}: {count}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-1131446826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. Apply SMOTE to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 3. Instantiate RandomUnderSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    907\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    908\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   2254\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    903\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    904\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m_matmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;34mf\"{err_prefix} (n,k={N}),(k={other.shape[0]},m)->(n,m)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 )\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m_matmul_sparse\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         csr_matmat(M, N,\n\u001b[0m\u001b[1;32m    463\u001b[0m                    \u001b[0ms_indptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                    \u001b[0mo_indptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}