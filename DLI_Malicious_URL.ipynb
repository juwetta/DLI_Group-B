{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfi8Aq2VSXOnc2v+CpNqrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juwetta/DLI_Group-B/blob/main/DLI_Malicious_URL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0TmHpBRdt1V",
        "outputId": "1c6d99b0-902f-44a5-aa78-59506df8f928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import imporant libraries"
      ],
      "metadata": {
        "id": "W661yBy9oQiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import glob\n",
        "import scipy.sparse\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2rPIABucoPoQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[code below is used for lower the size of dataset, since the full dataset can used up all the RAM just to storing them]"
      ],
      "metadata": {
        "id": "tBTgFy_JS4WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# # Define the source folder path\n",
        "# source_folder = '/content/drive/My Drive/DLI Group B/url_svmlight'\n",
        "\n",
        "# # Define the destination folder path\n",
        "# destination_folder = '/content/drive/My Drive/DLI Group B/url_dataset'\n",
        "\n",
        "# # Create the destination folder if it doesn't exist\n",
        "# os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# # List of files to copy (Day0.svm to Day60.svm and FeatureTypes)\n",
        "# files_to_copy = [f'Day{i}.svm' for i in range(61)] + ['FeatureTypes']\n",
        "\n",
        "# print(f\"Copying files to: {destination_folder}\")\n",
        "\n",
        "# # Copy the specified files\n",
        "# for file_name in files_to_copy:\n",
        "#     source_file_path = os.path.join(source_folder, file_name)\n",
        "#     destination_file_path = os.path.join(destination_folder, file_name)\n",
        "#     try:\n",
        "#         shutil.copy2(source_file_path, destination_file_path)\n",
        "#         print(f\"Copied: {file_name}\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"Warning: File not found - {file_name}. Skipping.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error copying file {file_name}: {e}\")\n",
        "\n",
        "# print(\"File copying process completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU_Rvf6xR39n",
        "outputId": "292da051-a9ee-4597-dfd7-b99f9ff4e583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying files to: /content/drive/My Drive/DLI Group B/url_dataset\n",
            "Copied: Day0.svm\n",
            "Copied: Day1.svm\n",
            "Copied: Day2.svm\n",
            "Copied: Day3.svm\n",
            "Copied: Day4.svm\n",
            "Copied: Day5.svm\n",
            "Copied: Day6.svm\n",
            "Copied: Day7.svm\n",
            "Copied: Day8.svm\n",
            "Copied: Day9.svm\n",
            "Copied: Day10.svm\n",
            "Copied: Day11.svm\n",
            "Copied: Day12.svm\n",
            "Copied: Day13.svm\n",
            "Copied: Day14.svm\n",
            "Copied: Day15.svm\n",
            "Copied: Day16.svm\n",
            "Copied: Day17.svm\n",
            "Copied: Day18.svm\n",
            "Copied: Day19.svm\n",
            "Copied: Day20.svm\n",
            "Copied: Day21.svm\n",
            "Copied: Day22.svm\n",
            "Copied: Day23.svm\n",
            "Copied: Day24.svm\n",
            "Copied: Day25.svm\n",
            "Copied: Day26.svm\n",
            "Copied: Day27.svm\n",
            "Copied: Day28.svm\n",
            "Copied: Day29.svm\n",
            "Copied: Day30.svm\n",
            "Copied: Day31.svm\n",
            "Copied: Day32.svm\n",
            "Copied: Day33.svm\n",
            "Copied: Day34.svm\n",
            "Copied: Day35.svm\n",
            "Copied: Day36.svm\n",
            "Copied: Day37.svm\n",
            "Copied: Day38.svm\n",
            "Copied: Day39.svm\n",
            "Copied: Day40.svm\n",
            "Copied: Day41.svm\n",
            "Copied: Day42.svm\n",
            "Copied: Day43.svm\n",
            "Copied: Day44.svm\n",
            "Copied: Day45.svm\n",
            "Copied: Day46.svm\n",
            "Copied: Day47.svm\n",
            "Copied: Day48.svm\n",
            "Copied: Day49.svm\n",
            "Copied: Day50.svm\n",
            "Copied: Day51.svm\n",
            "Copied: Day52.svm\n",
            "Copied: Day53.svm\n",
            "Copied: Day54.svm\n",
            "Copied: Day55.svm\n",
            "Copied: Day56.svm\n",
            "Copied: Day57.svm\n",
            "Copied: Day58.svm\n",
            "Copied: Day59.svm\n",
            "Copied: Day60.svm\n",
            "Copied: FeatureTypes\n",
            "File copying process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing to folder"
      ],
      "metadata": {
        "id": "AzFwtL3ZoWsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/DLI Group B/url_dataset'\n",
        "\n",
        "svm_files = glob.glob(os.path.join(folder_path, \"*.svm\"))\n",
        "print(f\"Found {len(svm_files)} SVM files in: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLsnaAxMobYW",
        "outputId": "335678db-f651-4d5a-eb16-f8ad9969099d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 61 SVM files in: /content/drive/My Drive/DLI Group B/url_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of the output, \"shape\" refers to the dimensions of the data structure (like a NumPy array or a SciPy sparse matrix).\n",
        "\n",
        "For a 2D structure like combined_X, the shape (2396130, 3231961) means it has 2,396,130 rows and 3,231,961 columns. In this dataset, the rows represent the samples (e.g., URLs), and the columns represent the features.\n",
        "For a 1D structure like combined_y, the shape (2396130,) means it has 2,396,130 elements. This corresponds to the labels for each of the samples in combined_X.\n",
        "So, the shape tells you how many samples you have and how many features or labels are associated with each sample."
      ],
      "metadata": {
        "id": "EPR2aZsXJWN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read SVM file and store dataset\n"
      ],
      "metadata": {
        "id": "MKkrToETooYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the different SVM files have varying numbers of features, causing an error when trying to combine them. I'll add a step to determine the total number of features across all files and then load each file with that consistent number of features."
      ],
      "metadata": {
        "id": "G1tzLDporKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max_features = 0\n",
        "\n",
        "# for file_path in svm_files:\n",
        "#   try:\n",
        "#     X, _ = load_svmlight_file(file_path)\n",
        "#     if X.shape[1] > max_features:\n",
        "#       max_features = X.shape[1]\n",
        "\n",
        "#   except Exception as e:\n",
        "#     print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "\n",
        "# print(f\"Maximum number of features found: {max_features}\") #74.777s used\n",
        "max_features = 3231961\n",
        "print(f\"Maximum number of features found: {max_features}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v3O3-CsqtRQ",
        "outputId": "c960ceda-68ee-462e-94ac-96b7dec28651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of features found: 3231961\n",
            "Maximum number of features found: 3231961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_X = []\n",
        "all_y = []\n",
        "max_features = 3231961\n",
        "try:\n",
        "    print(\"\\nLoading and combining data...\")\n",
        "\n",
        "    # Load and combine data in a single pass, specifying the number of features\n",
        "    for file_path in svm_files:\n",
        "        try:\n",
        "            X, y = load_svmlight_file(file_path, n_features=max_features)\n",
        "            all_X.append(X)\n",
        "            all_y.append(y)\n",
        "            print(f\"{os.path.basename(file_path)}\", end=\"| \")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "    if all_X and all_y:\n",
        "        # Vertically stack the sparse feature matrices\n",
        "        combined_X = scipy.sparse.vstack(all_X)\n",
        "        # Concatenate the label arrays\n",
        "        combined_y = np.concatenate(all_y)\n",
        "\n",
        "        print(\"\\nSuccessfully combined data from all files.\")\n",
        "        print(f\"Shape of combined data (X): {combined_X.shape}\")\n",
        "        print(f\"Shape of combined labels (y): {combined_y.shape}\")\n",
        "    else:\n",
        "        print(\"\\nNo data was loaded from the SVM files.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Folder not found at: {folder_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\") #75.54s used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIVvCQxf9EAH",
        "outputId": "04c6ed72-17d2-4377-861e-8f66159fe31e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading and combining data...\n",
            "Day0.svm| Day1.svm| Day2.svm| Day3.svm| Day4.svm| Day5.svm| Day6.svm| Day7.svm| Day8.svm| Day9.svm| Day10.svm| Day11.svm| Day12.svm| Day13.svm| Day14.svm| Day15.svm| Day16.svm| Day17.svm| Day18.svm| Day19.svm| Day20.svm| Day21.svm| Day22.svm| Day23.svm| Day24.svm| Day25.svm| Day26.svm| Day27.svm| Day28.svm| Day29.svm| Day30.svm| Day31.svm| Day32.svm| Day33.svm| Day34.svm| Day35.svm| Day36.svm| Day37.svm| Day38.svm| Day39.svm| Day40.svm| Day41.svm| Day42.svm| Day43.svm| Day44.svm| Day45.svm| Day46.svm| Day47.svm| Day48.svm| Day49.svm| Day50.svm| Day51.svm| Day52.svm| Day53.svm| Day54.svm| Day55.svm| Day56.svm| Day57.svm| Day58.svm| Day59.svm| Day60.svm| \n",
            "Successfully combined data from all files.\n",
            "Shape of combined data (X): (1196130, 3231961)\n",
            "Shape of combined labels (y): (1196130,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify the indexes of real-valued features"
      ],
      "metadata": {
        "id": "_YDHTWMvpDjk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad19fa23",
        "outputId": "0d72bb4c-641f-4ebd-be7b-df87a3d661ef"
      },
      "source": [
        "import os\n",
        "\n",
        "feature_types_path = '/content/drive/My Drive/DLI Group B/url_dataset/FeatureTypes'\n",
        "real_valued_feature_indices = set()\n",
        "\n",
        "try:\n",
        "    with open(feature_types_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Assuming each line in FeatureTypes is a feature index\n",
        "            try:\n",
        "                index = int(line.strip())\n",
        "                real_valued_feature_indices.add(index)\n",
        "            except ValueError:\n",
        "                # Handle potential non-integer lines in the file\n",
        "                print(f\"Skipping non-integer line in FeatureTypes: {line.strip()}\")\n",
        "\n",
        "    print(f\"Identified {len(real_valued_feature_indices)} real-valued feature indices.\")\n",
        "    # print(\"First 10 real-valued feature indices:\", list(real_valued_feature_indices)[:10]) # Optional: print a few indices\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"FeatureTypes file not found at: {feature_types_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading FeatureTypes: {e}\")\n",
        "\n",
        "# Now you have the set of real-valued feature indices and can use it\n",
        "# For example, you could filter your data or analyze these specific features."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 64 real-valued feature indices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Briefly explore the dataset"
      ],
      "metadata": {
        "id": "3d8LW7gkpK-3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e46d2c3",
        "outputId": "a26ca38f-4b9f-442f-f9aa-f57b02d935ae"
      },
      "source": [
        "# Select the first few rows to inspect\n",
        "num_rows_to_inspect = 5\n",
        "sample_rows = combined_X[:num_rows_to_inspect]\n",
        "\n",
        "print(f\"Values of real-valued features in the first {num_rows_to_inspect} rows:\")\n",
        "\n",
        "# Iterate through the selected rows\n",
        "for i in range(sample_rows.shape[0]):\n",
        "    print(f\"\\nRow {i+1}:\")\n",
        "    # Iterate through the real-valued feature indices\n",
        "    for feature_index in sorted(list(real_valued_feature_indices)): # Sorting for consistent output\n",
        "        # Check if the feature exists in the current row (i.e., it's non-zero)\n",
        "\n",
        "        if feature_index in sample_rows[i].indices:\n",
        "            # Get the index within the non-zero elements\n",
        "            data_index = np.where(sample_rows[i].indices == feature_index)[0][0]\n",
        "            # Get the value of the feature\n",
        "            feature_value = sample_rows[i].data[data_index]\n",
        "            print(f\"  Feature {feature_index}: {feature_value}\")\n",
        "        # If the feature index is not in sample_rows[i].indices, its value is 0 in the sparse matrix,\n",
        "        # so we don't need to explicitly print 0 unless we want to see all real-valued features\n",
        "        # even if their value is 0 for that sample. Let's only print non-zero real-valued features."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of real-valued features in the first 5 rows:\n",
            "\n",
            "Row 1:\n",
            "  Feature 4: 0.124138\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.749633\n",
            "  Feature 17: 0.843029\n",
            "  Feature 18: 0.197344\n",
            "  Feature 21: 0.142857\n",
            "  Feature 22: 0.142857\n",
            "  Feature 55: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 2:\n",
            "  Feature 4: 0.103448\n",
            "  Feature 5: 0.176471\n",
            "  Feature 16: 0.72266\n",
            "  Feature 17: 0.836498\n",
            "  Feature 18: 0.6189\n",
            "  Feature 21: 0.0119048\n",
            "  Feature 23: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 126: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 3:\n",
            "  Feature 4: 0.144828\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.760482\n",
            "  Feature 17: 0.820882\n",
            "  Feature 18: 0.150678\n",
            "  Feature 21: 0.142857\n",
            "  Feature 23: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "\n",
            "Row 4:\n",
            "  Feature 4: 0.0896552\n",
            "  Feature 5: 0.176471\n",
            "  Feature 21: 0.0238095\n",
            "  Feature 23: 1.0\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 150: 1.0\n",
            "\n",
            "Row 5:\n",
            "  Feature 4: 0.131034\n",
            "  Feature 5: 0.117647\n",
            "  Feature 16: 0.830283\n",
            "  Feature 17: 0.83965\n",
            "  Feature 18: 0.583194\n",
            "  Feature 19: 1.0\n",
            "  Feature 21: 0.00595238\n",
            "  Feature 22: 0.00595238\n",
            "  Feature 35: 1.0\n",
            "  Feature 43: 1.0\n",
            "  Feature 55: 1.0\n",
            "  Feature 61: 1.0\n",
            "  Feature 63: 1.0\n",
            "  Feature 65: 1.0\n",
            "  Feature 67: 1.0\n",
            "  Feature 69: 1.0\n",
            "  Feature 71: 1.0\n",
            "  Feature 73: 1.0\n",
            "  Feature 75: 1.0\n",
            "  Feature 81: 1.0\n",
            "  Feature 83: 1.0\n",
            "  Feature 85: 1.0\n",
            "  Feature 87: 1.0\n",
            "  Feature 89: 1.0\n",
            "  Feature 91: 1.0\n",
            "  Feature 93: 1.0\n",
            "  Feature 95: 1.0\n",
            "  Feature 101: 1.0\n",
            "  Feature 103: 1.0\n",
            "  Feature 105: 1.0\n",
            "  Feature 107: 1.0\n",
            "  Feature 109: 1.0\n",
            "  Feature 111: 1.0\n",
            "  Feature 132: 1.0\n",
            "  Feature 138: 1.0\n",
            "  Feature 140: 1.0\n",
            "  Feature 142: 1.0\n",
            "  Feature 144: 1.0\n",
            "  Feature 146: 1.0\n",
            "  Feature 148: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb21fdfb"
      },
      "source": [
        "# Task\n",
        "Balance the classes in the `combined_y` variable of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e12ae549"
      },
      "source": [
        "## Check class distribution\n",
        "\n",
        "### Subtask:\n",
        "Analyze the current distribution of the target variable (`combined_y`) to see how imbalanced the classes are.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed82c52"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and print the counts of each unique class in the `combined_y` array to understand the class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bb1f3a4",
        "outputId": "58409338-742a-4fd3-9547-d652b6aa50f0"
      },
      "source": [
        "unique_classes, class_counts = np.unique(combined_y, return_counts=True)\n",
        "\n",
        "print(\"Class distribution in combined_y:\")\n",
        "for class_val, count in zip(unique_classes, class_counts):\n",
        "    print(f\"Class {int(class_val)}: {count}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in combined_y:\n",
            "Class -1: 792438\n",
            "Class 1: 403692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ad112b"
      },
      "source": [
        "## Choose a balancing technique\n",
        "\n",
        "### Subtask:\n",
        "Decide on an appropriate method for balancing the classes, such as oversampling (e.g., SMOTE), undersampling, or a combination.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "562c76ef"
      },
      "source": [
        "## Apply the balancing technique\n",
        "\n",
        "### Subtask:\n",
        "Apply the balancing technique\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadc4dfd"
      },
      "source": [
        "**Reasoning**:\n",
        "To balance the dataset, I will first import the necessary libraries, `SMOTE` and `RandomUnderSampler`. Then, I will apply SMOTE to oversample the minority class, followed by RandomUnderSampler to undersample the majority class, as per the instructions. This will create a more balanced dataset for model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "24022c39",
        "outputId": "b982557f-f677-4f92-93dc-8b4351c4b6e1"
      },
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "\n",
        "# Instantiate NearMiss\n",
        "# NearMiss has different versions (1, 2, 3). You can experiment with them.\n",
        "# NearMiss-1 selects samples from the majority class whose average distance to the k nearest samples of the minority class is smallest.\n",
        "# NearMiss-2 selects samples from the majority class whose average distance to the k farthest samples of the minority class is smallest.\n",
        "# NearMiss-3 selects samples from the majority class whose distance to the k nearest samples of the minority class is largest.\n",
        "# Let's start with NearMiss-1.\n",
        "nm = NearMiss(version=1, sampling_strategy='auto', n_neighbors=3) # Adjust n_neighbors if needed\n",
        "\n",
        "print(\"Applying NearMiss undersampling...\")\n",
        "\n",
        "# Apply NearMiss to the data\n",
        "# NearMiss works directly on the original data\n",
        "X_resampled, y_resampled = nm.fit_resample(combined_X, combined_y)\n",
        "\n",
        "# Print the shapes of the resampled data to verify\n",
        "print(f\"Shape of X after NearMiss: {X_resampled.shape}\")\n",
        "print(f\"Shape of y after NearMiss: {y_resampled.shape}\")\n",
        "\n",
        "# Verify the new class distribution\n",
        "unique_classes_resampled, class_counts_resampled = np.unique(y_resampled, return_counts=True)\n",
        "print(\"\\nClass distribution after resampling:\")\n",
        "for class_val, count in zip(unique_classes_resampled, class_counts_resampled):\n",
        "    print(f\"Class {int(class_val)}: {count}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying NearMiss undersampling...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3694443281.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Apply NearMiss to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# NearMiss works directly on the original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Print the shapes of the resampled data to verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                     dist_vec, idx_vec = self.nn_.kneighbors(\n\u001b[0m\u001b[1;32m    248\u001b[0m                         \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    907\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    908\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2262\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \"\"\"\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}